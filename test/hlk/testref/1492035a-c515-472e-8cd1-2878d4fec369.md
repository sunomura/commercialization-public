---
title: Trim Performance Test
description: Trim Performance Test
MSHAttr:
- 'PreferredSiteName:MSDN'
- 'PreferredLib:/library/windows/hardware'
ms.assetid: 40982c0d-b9ac-4c8d-85ef-aeb7612d0648
---

# <span id="p_hlk_test.1492035a-c515-472e-8cd1-2878d4fec369"></span>Trim Performance Test


This test evaluates the performance of the trim command.

## <span id="Test_details"></span><span id="test_details"></span><span id="TEST_DETAILS"></span>Test details


<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Specifications</strong></td>
<td><ul>
<li>Device.Storage.Hd.Trim.BasicFunction</li>
</ul></td>
</tr>
<tr class="even">
<td><strong>Platforms</strong></td>
<td><ul>
<li>Windows 10 for desktop editions (Home, Pro, Enterprise, and Education) x86</li>
<li>Windows 10 for desktop editions x64</li>
<li>Windows Server 2016 x64</li>
</ul></td>
</tr>
<tr class="odd">
<td><strong>Supported Releases</strong></td>
<td><ul>
<li>Windows 10</li>
<li>Windows 10, version 1511</li>
<li>Windows 10, version 1607</li>
<li>Windows 10, version 1703</li>
</ul></td>
</tr>
<tr class="even">
<td><strong>Expected run time (in minutes)</strong></td>
<td>180</td>
</tr>
<tr class="odd">
<td><strong>Category</strong></td>
<td>Benchmark</td>
</tr>
<tr class="even">
<td><strong>Timeout (in minutes)</strong></td>
<td>10800</td>
</tr>
<tr class="odd">
<td><strong>Requires reboot</strong></td>
<td>false</td>
</tr>
<tr class="even">
<td><strong>Requires special configuration</strong></td>
<td>false</td>
</tr>
<tr class="odd">
<td><strong>Type</strong></td>
<td>automatic</td>
</tr>
</tbody>
</table>

 

## <span id="Additional_documentation"></span><span id="additional_documentation"></span><span id="ADDITIONAL_DOCUMENTATION"></span>Additional documentation


Tests in this feature area might have additional documentation, including prerequisites, setup, and troubleshooting information, that can be found in the following topic(s):

-   [Device.Storage additional documentation](device-storage-additional-documentation.md)

## <span id="Running_the_test"></span><span id="running_the_test"></span><span id="RUNNING_THE_TEST"></span>Running the test


Before you run the test, complete the test setup as described in the test requirements: [Hard Disk Drive Testing Prerequisites](hard-disk-drive-testing-prerequisites.md).

The device supporting trim must be attached to the appropriate controller. The job will prepare the disk with the correct partition and formatting for the testing. The test is destructive and therefore **the disk cannot be the boot drive**. Also, since the test logs large amounts of data, ensure that there is a separate drive available to be used as the logger drive. The test will automatically pick the logging drive. It is important to minimize the amount of activity occurring on the drive outside of the logo test. Since this is a performance test, outside activity may affect the results. Additionally, preconditioning the drive by writing data to fill up the drive before starting the test may give more consistent results. This is dependent on the drives implementation and may not be advantageous to all drives.

## <span id="Troubleshooting"></span><span id="troubleshooting"></span><span id="TROUBLESHOOTING"></span>Troubleshooting


For generic troubleshooting of HLK test failures, see [Troubleshooting Windows HLK Test Failures](..\user\troubleshooting-windows-hlk-test-failures.md).

-   Check WTT Trace

    -   View **Task Log** of **Run Trim Performance Test**.

    -   Open the log file **TrimPerf.wtl**.

    -   Check for messages that may solve the issue.

    -   Copy the .wtl log file. This is the WTT trace described in the WTT Trace section.

-   Check launched command results

    -   Browse Job Logs of Trim Performance Test (LOGO).

    -   Open the LaunchCommand.result.

    -   If the error is related to launching a process, determine why logman or tracerpt failed.

-   No metrics found

    -   The test depends on Storport ETW tracing being enabled in order to get the command completion metrics. See the ETW Trace section for more information about enabling this tracing.

    -   Ensure no other Storport ETW traces are currently logging. Only one Storport ETW trace can be active at a time.

-   If you get the error message “The test drive does not support trim”, try the following:

    -   Ensure that the SATA SSD’s IDENTIFY DEVICE data word 169 bit 0 is set to one.

    -   Try to send a Trim command via DATA SET MANAGEMENT.

    -   Run the test again.

-   If the test failed because the read and write maximum latency exceeded 500 milliseconds, try the following:

    -   Check the IO latency without Trim. Try to lower the latency below 500 milliseconds.

    -   Check the IO latency with presence of Trim. Try to lower the latency below 500 milliseconds.

-   If you want to debug the failure by running particular test cases, you may try the following command line options:

    -   Display all the test cases with numbers: **TrimPerf.exe /DriveNumber \[StorageDriveNumber\] /LogDriveLetter \[LoggerDriveLetter\]: /DeviceType StorConsumer /PrintTestCaseName**

    -   Run particular test case by test case number: **TrimPerf.exe /DriveNumber \[StorageDriveNumber\] /LogDriveLetter \[LoggerDriveLetter\]: /DeviceType StorConsumer /Precondition F /TestCase \[TestCaseNumber\]**

-   If you want to debug the failure by running particular pure Trim scenario, you may try the following command line options:

    -   The binary has unit test options: **TrimPerf.exe /DriveNumber \[StorageDriveNumber\] /LogDriveLetter \[LoggerDriveLetter\]: /DeviceType StorConsumer /Precondition F /UnitTest T /RangeCount \[NumberOfRangesPerTrim\] /SizeCount \[SizeOfEachRange\] /SizeUnit Sector /TrimCount \[NumberOfTrims\]**

    -   **/RangeCount**: The number of ranges per Trim command

    -   **/SizeCount**: The size of each range in /SizeUnit

    -   **/SizeUnit**: The granularity of /SizeCount, for SATA SSD, the granularity is sector.

    -   **/TrimCount**: The number of Trims sent in the test case.

-   If you want to debug the failure faster, try disable the preconditioning (fill up the drive to 90% full, takes long time) by adding /Precondition F parameter as follows:

    -   **TrimPerf.exe /DriveNumber \[StorageDriveNumber\] /LogDriveLetter \[LoggerDriveLetter\]: /DeviceType StorConsumer /Scenario Performance /DiskSize 0 /Cooldown 2 /Precondition F**

For more troubleshooting information, see [Troubleshooting Device.Storage Testing](troubleshooting-devicestorage-testing.md).

## <span id="More_information"></span><span id="more_information"></span><span id="MORE_INFORMATION"></span>More information


The job takes in the device instance ID of the device under test and converts the device instance ID to a physical drive number. The job partitions and formats the drive to get it into the configuration needed for testing. The test will run through a series of test cases each mapped to items in the requirements. The test cases are self-contained and are run sequentially. A list of test cases can be obtained by using the PrintTestCaseName command line option with the appropriate device specified. Each of these test cases can be run on the command line using the test in standalone mode for further testing or debugging.

The Trim Performance test stores a policy table defining for each type of device what performance tests are to be run and what the appropriate metrics should be. Once the appropriate items in the table are selected, the test will sequentially spawn threads defined in the table for that device. Each thread will execute according to the parameters specified in the table. Once the stop conditions for each of the threads has been satisfied, the threads will stop execution and the results will be parsed to generate the pass/fail logs.

The test generates large performance logs and in order to not affect the performance of the drive being tested, these logs are written to a separate drive. The drive is automatically chosen by the job, but can alternatively be specified on the command line

The test commands are as follows:

**Trim command**

All trim commands should be completed in less than 500 milliseconds.

**IO command (with Trim sending at same time)**

-   All read and write commands complete in less than 500 milliseconds.

-   98.5% of I/O commands complete in less than 100 milliseconds.

### <span id="Command_syntax"></span><span id="command_syntax"></span><span id="COMMAND_SYNTAX"></span>Command syntax

<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Command option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><strong>TrimPerf.exe /DriveNumber [StorageDriveNumber] /LogDriveLetter [LogDriveLetter]: /DeviceType StorConsumer /Scenario Performance /DiskSize 0 /Cooldown 2</strong></p></td>
<td></td>
</tr>
<tr class="even">
<td><p>Runs the test.</p></td>
<td></td>
</tr>
</tbody>
</table>

>[!NOTE]
>  
For command-line help for this test binary, type **/h**.

 

### <span id="File_list"></span><span id="file_list"></span><span id="FILE_LIST"></span>File list

<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>File</th>
<th>Location</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>TrimPerf.exe</p></td>
<td><p><em>&lt;[testbinroot]&gt;</em>\nttest\driverstest\storage\wdk\</p></td>
</tr>
<tr class="even">
<td><p>Etwprocessor.dll</p></td>
<td><p><em>&lt;[taefbinroot]&gt;</em>\</p></td>
</tr>
<tr class="odd">
<td><p>Wex.common.dll</p></td>
<td><p><em>&lt;[taefbinroot]&gt;</em>\</p></td>
</tr>
<tr class="even">
<td><p>Wex.communication.dll</p></td>
<td><p><em>&lt;[taefbinroot]&gt;</em>\</p></td>
</tr>
</tbody>
</table>

 

### <span id="Parameters"></span><span id="parameters"></span><span id="PARAMETERS"></span>Parameters

| Parameter name              | Parameter description                      |
|-----------------------------|--------------------------------------------|
| **WDKDeviceID**             | Instance path of device to test.           |
| **LLU\_NetAccessOnly**      | User account for accessing test fileshare. |
| **LLU\_LclAdminUsr**        | User account for running the test.         |
| **Destructive**             | (0,1) 0=Passive, 1=Destructive             |
| **StorageDriveNumber**      | Storage drive number                       |
| **QueryStorage\_bus\_type** | Storage bus type                           |

 

 

 






